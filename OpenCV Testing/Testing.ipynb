{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de7db694f6833c07",
   "metadata": {},
   "source": [
    "# Person Detection and Movement Tracking System\n",
    "\n",
    "This system uses OpenCV to detect people via webcam and tracks their movements to identify:\n",
    "- People walking back and forth\n",
    "- Anyone approaching your computer\n",
    "- Real-time alerts for suspicious activity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d1f5a12588bc4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T22:29:24.764160Z",
     "start_time": "2025-07-17T22:29:24.744768Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import pygame\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Initialize pygame for sound alerts\n",
    "pygame.mixer.init()\n",
    "\n",
    "class MultiModelPersonDetector:\n",
    "    def __init__(self):\n",
    "        # Available detection models\n",
    "        self.models = {\n",
    "            'hog': 'HOG + SVM (OpenCV)',\n",
    "            'yolo': 'YOLOv8 (Ultralytics)',\n",
    "            'mobilenet': 'MobileNet SSD (OpenCV DNN)',\n",
    "            'cascade': 'Haar Cascade (OpenCV)',\n",
    "            'background_subtraction': 'Background Subtraction + Contours'\n",
    "        }\n",
    "\n",
    "        self.current_model = 'yolo'\n",
    "        self.model_objects = {}\n",
    "\n",
    "        # Initialize all models\n",
    "        self._initialize_models()\n",
    "\n",
    "        # Movement tracking\n",
    "        self.person_tracks = {}\n",
    "        self.track_id = 0\n",
    "        self.approach_threshold = 0.3\n",
    "        self.oscillation_threshold = 3\n",
    "\n",
    "        # Alert settings\n",
    "        self.last_alert_time = 0\n",
    "        self.alert_cooldown = 5\n",
    "\n",
    "        # Statistics\n",
    "        self.detection_count = 0\n",
    "        self.approach_alerts = 0\n",
    "        self.pacing_alerts = 0\n",
    "\n",
    "        # Performance tracking\n",
    "        self.fps_history = deque(maxlen=30)\n",
    "        self.detection_confidence = deque(maxlen=30)\n",
    "\n",
    "    def _initialize_models(self):\n",
    "        \"\"\"Initialize all detection models\"\"\"\n",
    "        print(\"Initializing detection models...\")\n",
    "\n",
    "        # 1. HOG + SVM\n",
    "        try:\n",
    "            hog = cv2.HOGDescriptor()\n",
    "            hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "            self.model_objects['hog'] = hog\n",
    "            print(\"✓ HOG + SVM initialized\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ HOG + SVM failed: {e}\")\n",
    "\n",
    "        # 2. YOLOv8\n",
    "        try:\n",
    "            from ultralytics import YOLO\n",
    "            import torch\n",
    "            device = 'mps' if hasattr(torch, 'backends') and torch.backends.mps.is_available() else 'cpu'\n",
    "            yolo_model = YOLO('yolov8n.pt')\n",
    "            yolo_model.to(device)\n",
    "            self.model_objects['yolo'] = yolo_model\n",
    "            print(f\"✓ YOLOv8 initialized on device: {device}\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ YOLOv8 failed: {e}\")\n",
    "\n",
    "        # 3. MobileNet SSD\n",
    "        try:\n",
    "            # Download MobileNet SSD model if not exists\n",
    "            model_dir = Path(\"models\")\n",
    "            model_dir.mkdir(exist_ok=True)\n",
    "\n",
    "            config_path = model_dir / \"MobileNetSSD_deploy.prototxt\"\n",
    "            weights_path = model_dir / \"MobileNetSSD_deploy.caffemodel\"\n",
    "\n",
    "            # For demo purposes, we'll use a simpler approach\n",
    "            # You can manually download these files if needed\n",
    "            try:\n",
    "                net = cv2.dnn.readNetFromCaffe(str(config_path), str(weights_path))\n",
    "                self.model_objects['mobilenet'] = net\n",
    "                print(\"✓ MobileNet SSD initialized\")\n",
    "            except:\n",
    "                print(\"✗ MobileNet SSD files not found (download required)\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ MobileNet SSD failed: {e}\")\n",
    "\n",
    "        # 4. Haar Cascade\n",
    "        try:\n",
    "            # Use correct path to cascade file\n",
    "            cascade_path = os.path.join(cv2.data.haarcascades, 'haarcascade_fullbody.xml')\n",
    "            if os.path.exists(cascade_path):\n",
    "                cascade = cv2.CascadeClassifier(cascade_path)\n",
    "                self.model_objects['cascade'] = cascade\n",
    "                print(\"✓ Haar Cascade initialized\")\n",
    "            else:\n",
    "                print(\"✗ Haar Cascade file not found\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Haar Cascade failed: {e}\")\n",
    "\n",
    "        # 5. Background Subtraction\n",
    "        try:\n",
    "            bg_subtractor = cv2.createBackgroundSubtractorMOG2(detectShadows=True)\n",
    "            self.model_objects['background_subtraction'] = bg_subtractor\n",
    "            print(\"✓ Background Subtraction initialized\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Background Subtraction failed: {e}\")\n",
    "\n",
    "    def switch_model(self, model_name):\n",
    "        \"\"\"Switch to a different detection model\"\"\"\n",
    "        if model_name in self.models and model_name in self.model_objects:\n",
    "            self.current_model = model_name\n",
    "            print(f\"Switched to: {self.models[model_name]}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Model '{model_name}' not available\")\n",
    "            return False\n",
    "\n",
    "    def detect_people_hog(self, frame):\n",
    "        \"\"\"HOG + SVM detection\"\"\"\n",
    "        if 'hog' not in self.model_objects:\n",
    "            return [], []\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        boxes, weights = self.model_objects['hog'].detectMultiScale(\n",
    "            gray,\n",
    "            winStride=(8, 8),\n",
    "            padding=(32, 32),\n",
    "            scale=1.05\n",
    "        )\n",
    "\n",
    "        # Convert to [x1, y1, x2, y2] format\n",
    "        boxes = np.array([[x, y, x + w, y + h] for (x, y, w, h) in boxes])\n",
    "        return boxes, weights\n",
    "\n",
    "    def detect_people_yolo(self, frame):\n",
    "        \"\"\"YOLOv8 detection\"\"\"\n",
    "        if 'yolo' not in self.model_objects:\n",
    "            return [], []\n",
    "\n",
    "        results = self.model_objects['yolo'](frame, verbose=False)\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "\n",
    "        for result in results:\n",
    "            for box in result.boxes:\n",
    "                if box.cls == 0:  # Person class\n",
    "                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                    boxes.append([int(x1), int(y1), int(x2), int(y2)])\n",
    "                    confidences.append(float(box.conf))\n",
    "\n",
    "        return np.array(boxes), np.array(confidences)\n",
    "\n",
    "    def detect_people_mobilenet(self, frame):\n",
    "        \"\"\"MobileNet SSD detection\"\"\"\n",
    "        if 'mobilenet' not in self.model_objects:\n",
    "            return [], []\n",
    "\n",
    "        h, w = frame.shape[:2]\n",
    "        blob = cv2.dnn.blobFromImage(frame, 0.007843, (300, 300), (127.5, 127.5, 127.5))\n",
    "\n",
    "        net = self.model_objects['mobilenet']\n",
    "        net.setInput(blob)\n",
    "        detections = net.forward()\n",
    "\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "\n",
    "        for i in range(detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            class_id = int(detections[0, 0, i, 1])\n",
    "\n",
    "            if class_id == 15 and confidence > 0.5:  # Person class\n",
    "                x1 = int(detections[0, 0, i, 3] * w)\n",
    "                y1 = int(detections[0, 0, i, 4] * h)\n",
    "                x2 = int(detections[0, 0, i, 5] * w)\n",
    "                y2 = int(detections[0, 0, i, 6] * h)\n",
    "\n",
    "                boxes.append([x1, y1, x2, y2])\n",
    "                confidences.append(confidence)\n",
    "\n",
    "        return np.array(boxes), np.array(confidences)\n",
    "\n",
    "    def detect_people_cascade(self, frame):\n",
    "        \"\"\"Haar Cascade detection\"\"\"\n",
    "        if 'cascade' not in self.model_objects:\n",
    "            return [], []\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        bodies = self.model_objects['cascade'].detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=3,\n",
    "            minSize=(30, 30)\n",
    "        )\n",
    "\n",
    "        # Convert to [x1, y1, x2, y2] format\n",
    "        boxes = np.array([[x, y, x + w, y + h] for (x, y, w, h) in bodies])\n",
    "        weights = np.ones(len(boxes))  # No confidence scores from cascade\n",
    "\n",
    "        return boxes, weights\n",
    "\n",
    "    def detect_people_background_subtraction(self, frame):\n",
    "        \"\"\"Background subtraction with contour detection\"\"\"\n",
    "        if 'background_subtraction' not in self.model_objects:\n",
    "            return [], []\n",
    "\n",
    "        # Apply background subtraction\n",
    "        fg_mask = self.model_objects['background_subtraction'].apply(frame)\n",
    "\n",
    "        # Morphological operations to clean up the mask\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "        fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "\n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area > 500:  # Filter small contours\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                # Filter by aspect ratio (rough person shape)\n",
    "                aspect_ratio = h / w\n",
    "                if 1.2 < aspect_ratio < 4.0:\n",
    "                    boxes.append([x, y, x + w, y + h])\n",
    "                    confidences.append(area / 10000)  # Use area as confidence\n",
    "\n",
    "        return np.array(boxes), np.array(confidences)\n",
    "\n",
    "    def detect_people(self, frame):\n",
    "        \"\"\"Detect people using the current model\"\"\"\n",
    "        start_time = time.time()\n",
    "\n",
    "        if self.current_model == 'hog':\n",
    "            boxes, weights = self.detect_people_hog(frame)\n",
    "        elif self.current_model == 'yolo':\n",
    "            boxes, weights = self.detect_people_yolo(frame)\n",
    "        elif self.current_model == 'mobilenet':\n",
    "            boxes, weights = self.detect_people_mobilenet(frame)\n",
    "        elif self.current_model == 'cascade':\n",
    "            boxes, weights = self.detect_people_cascade(frame)\n",
    "        elif self.current_model == 'background_subtraction':\n",
    "            boxes, weights = self.detect_people_background_subtraction(frame)\n",
    "        else:\n",
    "            boxes, weights = [], []\n",
    "\n",
    "        # Calculate FPS\n",
    "        detection_time = time.time() - start_time\n",
    "        fps = 1.0 / detection_time if detection_time > 0 else 0\n",
    "        self.fps_history.append(fps)\n",
    "\n",
    "        # Store average confidence\n",
    "        if len(weights) > 0:\n",
    "            avg_confidence = np.mean(weights)\n",
    "            self.detection_confidence.append(avg_confidence)\n",
    "\n",
    "        return boxes, weights\n",
    "\n",
    "    def calculate_distance_to_camera(self, box):\n",
    "        \"\"\"Calculate relative distance to camera based on bounding box size\"\"\"\n",
    "        x1, y1, x2, y2 = box\n",
    "        w = x2 - x1\n",
    "        h = y2 - y1\n",
    "        # Larger boxes are closer to camera\n",
    "        return 1.0 / (w * h / 10000)  # Normalized distance metric\n",
    "\n",
    "    def track_movement(self, boxes, frame_center):\n",
    "        \"\"\"Track person movement and detect patterns\"\"\"\n",
    "        current_time = time.time()\n",
    "        frame_height, frame_width = frame_center\n",
    "\n",
    "        alerts = []\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box\n",
    "            center_x = (x1 + x2) // 2\n",
    "            center_y = (y1 + y2) // 2\n",
    "\n",
    "            # Calculate distance to camera\n",
    "            distance = self.calculate_distance_to_camera(box)\n",
    "\n",
    "            # Find closest existing track or create new one\n",
    "            min_distance = float('inf')\n",
    "            closest_track = None\n",
    "\n",
    "            for track_id, track_data in self.person_tracks.items():\n",
    "                if track_data['positions']:\n",
    "                    last_pos = track_data['positions'][-1]\n",
    "                    dist = np.sqrt((center_x - last_pos[0])**2 + (center_y - last_pos[1])**2)\n",
    "                    if dist < min_distance and dist < 100:  # Maximum movement threshold\n",
    "                        min_distance = dist\n",
    "                        closest_track = track_id\n",
    "\n",
    "            if closest_track is None:\n",
    "                # Create new track\n",
    "                self.track_id += 1\n",
    "                self.person_tracks[self.track_id] = {\n",
    "                    'positions': deque(maxlen=30),  # Keep last 30 positions\n",
    "                    'distances': deque(maxlen=30),\n",
    "                    'timestamps': deque(maxlen=30),\n",
    "                    'direction_changes': 0,\n",
    "                    'last_direction': None,\n",
    "                    'approaching': False\n",
    "                }\n",
    "                closest_track = self.track_id\n",
    "\n",
    "            # Update track\n",
    "            track = self.person_tracks[closest_track]\n",
    "            track['positions'].append((center_x, center_y))\n",
    "            track['distances'].append(distance)\n",
    "            track['timestamps'].append(current_time)\n",
    "\n",
    "            # Detect approaching behavior\n",
    "            if len(track['distances']) >= 5:\n",
    "                recent_distances = list(track['distances'])[-5:]\n",
    "                if all(recent_distances[i] < recent_distances[i-1] for i in range(1, len(recent_distances))):\n",
    "                    if distance < self.approach_threshold and not track['approaching']:\n",
    "                        track['approaching'] = True\n",
    "                        alerts.append(f\"Person {closest_track} is approaching the camera!\")\n",
    "                        self.approach_alerts += 1\n",
    "                elif distance > self.approach_threshold:\n",
    "                    track['approaching'] = False\n",
    "\n",
    "            # Detect pacing/oscillation\n",
    "            if len(track['positions']) >= 3:\n",
    "                positions = list(track['positions'])\n",
    "                # Calculate movement direction\n",
    "                recent_direction = \"left\" if positions[-1][0] < positions[-3][0] else \"right\"\n",
    "\n",
    "                if track['last_direction'] and track['last_direction'] != recent_direction:\n",
    "                    track['direction_changes'] += 1\n",
    "\n",
    "                    if track['direction_changes'] >= self.oscillation_threshold:\n",
    "                        alerts.append(f\"Person {closest_track} is pacing back and forth!\")\n",
    "                        self.pacing_alerts += 1\n",
    "                        track['direction_changes'] = 0  # Reset counter\n",
    "\n",
    "                track['last_direction'] = recent_direction\n",
    "\n",
    "        # Clean up old tracks\n",
    "        current_time = time.time()\n",
    "        tracks_to_remove = []\n",
    "        for track_id, track_data in self.person_tracks.items():\n",
    "            if track_data['timestamps'] and current_time - track_data['timestamps'][-1] > 5:\n",
    "                tracks_to_remove.append(track_id)\n",
    "\n",
    "        for track_id in tracks_to_remove:\n",
    "            del self.person_tracks[track_id]\n",
    "\n",
    "        return alerts\n",
    "\n",
    "    def play_alert_sound(self):\n",
    "        \"\"\"Play alert sound (beep)\"\"\"\n",
    "        try:\n",
    "            # Create a simple beep sound\n",
    "            sample_rate = 22050\n",
    "            duration = 0.5\n",
    "            frequency = 800\n",
    "\n",
    "            frames = int(duration * sample_rate)\n",
    "            arr = np.sin(2 * np.pi * frequency * np.linspace(0, duration, frames))\n",
    "            arr = (arr * 32767).astype(np.int16)\n",
    "\n",
    "            sound = pygame.sndarray.make_sound(arr)\n",
    "            sound.play()\n",
    "        except:\n",
    "            print(\"ALERT!\")  # Fallback if sound fails\n",
    "\n",
    "    def draw_detections(self, frame, boxes, alerts):\n",
    "        \"\"\"Draw bounding boxes and information on frame\"\"\"\n",
    "        for i, box in enumerate(boxes):\n",
    "            x1, y1, x2, y2 = box\n",
    "\n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "            # Calculate and display distance\n",
    "            distance = self.calculate_distance_to_camera(box)\n",
    "            cv2.putText(frame, f\"Dist: {distance:.2f}\", (x1, y1-10),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "        # Display current model\n",
    "        cv2.putText(frame, f\"Model: {self.models[self.current_model]}\",\n",
    "                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "\n",
    "        # Display FPS\n",
    "        if self.fps_history:\n",
    "            avg_fps = np.mean(list(self.fps_history))\n",
    "            cv2.putText(frame, f\"FPS: {avg_fps:.1f}\",\n",
    "                       (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "\n",
    "        # Display alerts\n",
    "        for i, alert in enumerate(alerts):\n",
    "            cv2.putText(frame, alert, (10, 90 + i*30),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "        # Display statistics\n",
    "        stats = [\n",
    "            f\"People detected: {len(boxes)}\",\n",
    "            f\"Total detections: {self.detection_count}\",\n",
    "            f\"Approach alerts: {self.approach_alerts}\",\n",
    "            f\"Pacing alerts: {self.pacing_alerts}\"\n",
    "        ]\n",
    "\n",
    "        for i, stat in enumerate(stats):\n",
    "            cv2.putText(frame, stat, (10, frame.shape[0] - 120 + i*20),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "        # Model switching instructions\n",
    "        instructions = [\n",
    "            \"Model Controls:\",\n",
    "            \"1-HOG  2-YOLO  3-MobileNet\",\n",
    "            \"4-Cascade  5-Background Sub\"\n",
    "        ]\n",
    "\n",
    "        for i, instruction in enumerate(instructions):\n",
    "            cv2.putText(frame, instruction, (frame.shape[1] - 300, 30 + i*20),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (200, 200, 200), 1)\n",
    "\n",
    "        return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c17d7c09ae22a724",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T22:29:24.773290Z",
     "start_time": "2025-07-17T22:29:24.769284Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_person_detection():\n",
    "    \"\"\"Main function to run the person detection system\"\"\"\n",
    "    detector = MultiModelPersonDetector()\n",
    "\n",
    "    # Initialize webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam\")\n",
    "        return\n",
    "\n",
    "    print(\"Person Detection System Started\")\n",
    "    print(\"Press 'q' to quit\")\n",
    "    print(\"Press 's' to save screenshot\")\n",
    "    print(\"Press 'r' to reset statistics\")\n",
    "    print(\"Press '1-5' to switch between detection models:\")\n",
    "    print(\"  1 - HOG + SVM (Default)\")\n",
    "    print(\"  2 - YOLOv8 (Best accuracy)\")\n",
    "    print(\"  3 - MobileNet SSD\")\n",
    "    print(\"  4 - Haar Cascade\")\n",
    "    print(\"  5 - Background Subtraction\")\n",
    "\n",
    "    screenshot_count = 0\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Error: Could not read frame\")\n",
    "                break\n",
    "\n",
    "            # Detect people\n",
    "            boxes, weights = detector.detect_people(frame)\n",
    "            detector.detection_count += len(boxes)\n",
    "\n",
    "            # Track movement and get alerts\n",
    "            frame_center = (frame.shape[0], frame.shape[1])\n",
    "            alerts = detector.track_movement(boxes, frame_center)\n",
    "\n",
    "            # Handle alerts\n",
    "            current_time = time.time()\n",
    "            if alerts and current_time - detector.last_alert_time > detector.alert_cooldown:\n",
    "                detector.play_alert_sound()\n",
    "                detector.last_alert_time = current_time\n",
    "                print(f\"[{datetime.now().strftime('%H:%M:%S')}] ALERTS: {', '.join(alerts)}\")\n",
    "\n",
    "            # Draw detections and information\n",
    "            frame = detector.draw_detections(frame, boxes, alerts)\n",
    "\n",
    "            # Display frame\n",
    "            cv2.imshow('Person Detection - Security Monitor', frame)\n",
    "\n",
    "            # Handle key presses\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "            elif key == ord('s'):\n",
    "                screenshot_count += 1\n",
    "                filename = f\"data/screenshot_{screenshot_count}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jpg\"\n",
    "                cv2.imwrite(filename, frame)\n",
    "                print(f\"Screenshot saved: {filename}\")\n",
    "            elif key == ord('r'):\n",
    "                detector.detection_count = 0\n",
    "                detector.approach_alerts = 0\n",
    "                detector.pacing_alerts = 0\n",
    "                detector.person_tracks.clear()\n",
    "                print(\"Statistics reset\")\n",
    "            elif key == ord('1'):\n",
    "                detector.switch_model('hog')\n",
    "            elif key == ord('2'):\n",
    "                detector.switch_model('yolo')\n",
    "            elif key == ord('3'):\n",
    "                detector.switch_model('mobilenet')\n",
    "            elif key == ord('4'):\n",
    "                detector.switch_model('cascade')\n",
    "            elif key == ord('5'):\n",
    "                detector.switch_model('background_subtraction')\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nStopping detection system...\")\n",
    "\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"Person detection system stopped\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f7037997732b44c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T22:29:24.780351Z",
     "start_time": "2025-07-17T22:29:24.777561Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model comparison tool\n",
    "def compare_models():\n",
    "    \"\"\"Compare performance of different detection models\"\"\"\n",
    "    detector = MultiModelPersonDetector()\n",
    "\n",
    "    # Test each model on a sample frame\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam\")\n",
    "        return\n",
    "\n",
    "    ret, test_frame = cap.read()\n",
    "    cap.release()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Error: Could not capture test frame\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nModel Performance Comparison:\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for model_name in detector.models.keys():\n",
    "        if model_name in detector.model_objects:\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Switch to model and detect\n",
    "            detector.switch_model(model_name)\n",
    "            boxes, weights = detector.detect_people(test_frame)\n",
    "\n",
    "            detection_time = time.time() - start_time\n",
    "            fps = 1.0 / detection_time if detection_time > 0 else 0\n",
    "\n",
    "            results[model_name] = {\n",
    "                'detections': len(boxes),\n",
    "                'fps': fps,\n",
    "                'avg_confidence': np.mean(weights) if len(weights) > 0 else 0\n",
    "            }\n",
    "\n",
    "            print(f\"{detector.models[model_name]}:\")\n",
    "            print(f\"  Detections: {len(boxes)}\")\n",
    "            print(f\"  FPS: {fps:.1f}\")\n",
    "            print(f\"  Avg Confidence: {results[model_name]['avg_confidence']:.2f}\")\n",
    "            print()\n",
    "\n",
    "    # Recommend best model\n",
    "    if results:\n",
    "        best_fps = max(results.items(), key=lambda x: x[1]['fps'])\n",
    "        best_detections = max(results.items(), key=lambda x: x[1]['detections'])\n",
    "\n",
    "        print(\"Recommendations:\")\n",
    "        print(f\"  Best Speed: {detector.models[best_fps[0]]} ({best_fps[1]['fps']:.1f} FPS)\")\n",
    "        print(f\"  Most Detections: {detector.models[best_detections[0]]} ({best_detections[1]['detections']} people)\")\n",
    "\n",
    "# Uncomment to run model comparison\n",
    "# compare_models()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596453e22762cc1c",
   "metadata": {},
   "source": [
    "# Advanced Features\n",
    "\n",
    "You can extend this system with:\n",
    "- Face recognition to identify specific individuals\n",
    "- Motion history tracking\n",
    "- Email/SMS alerts for security breaches\n",
    "- Integration with home automation systems\n",
    "- Multiple camera support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9783d0aae4d9667",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T22:29:24.785404Z",
     "start_time": "2025-07-17T22:29:24.783628Z"
    }
   },
   "outputs": [],
   "source": [
    "# Optional: Analyze detection patterns\n",
    "def analyze_detection_patterns():\n",
    "    \"\"\"Analyze patterns in the detection data\"\"\"\n",
    "    # This would analyze stored detection data\n",
    "    # For now, just show how to visualize detection frequency\n",
    "\n",
    "    # Example visualization\n",
    "    times = [datetime.now().hour + np.random.randint(-2, 3) for _ in range(50)]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(times, bins=24, alpha=0.7, color='blue')\n",
    "    plt.xlabel('Hour of Day')\n",
    "    plt.ylabel('Detection Frequency')\n",
    "    plt.title('Person Detection Frequency by Hour')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# Uncomment to run analysis\n",
    "# analyze_detection_patterns()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df7ede98ceaf243",
   "metadata": {},
   "source": [
    "# Interactive Model Selection\n",
    "\n",
    "Run the cell below to start the person detection system with an interactive model selection menu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d595725d63c2f77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T22:32:35.752387Z",
     "start_time": "2025-07-17T22:29:24.788244Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Person Detection System - Interactive Model Selection\n",
      "============================================================\n",
      "Initializing detection models...\n",
      "✓ HOG + SVM initialized\n",
      "✓ YOLOv8 initialized\n",
      "✗ MobileNet SSD files not found (download required)\n",
      "✓ Haar Cascade initialized\n",
      "✓ Background Subtraction initialized\n",
      "\n",
      "Available Detection Models:\n",
      "------------------------------\n",
      "  1. HOG + SVM (OpenCV) ✓\n",
      "  2. YOLOv8 (Ultralytics) ✓\n",
      "  3. MobileNet SSD (OpenCV DNN) ✗ (Not available)\n",
      "  4. Haar Cascade (OpenCV) ✓\n",
      "  5. Background Subtraction + Contours ✓\n",
      "\n",
      "📊 Quick Performance Test:\n",
      "------------------------------\n",
      "Switched to: HOG + SVM (OpenCV)\n",
      "  HOG + SVM (OpenCV): 0 detections, 2.1 FPS\n",
      "Switched to: YOLOv8 (Ultralytics)\n",
      "  YOLOv8 (Ultralytics): 2 detections, 1.2 FPS\n",
      "Switched to: Haar Cascade (OpenCV)\n",
      "  Haar Cascade (OpenCV): 0 detections, 41.3 FPS\n",
      "Switched to: Background Subtraction + Contours\n",
      "  Background Subtraction + Contours: 0 detections, 30.8 FPS\n",
      "\n",
      "🚀 Choose a model to start detection:\n",
      "----------------------------------------\n",
      "  1. HOG + SVM (OpenCV)\n",
      "  2. YOLOv8 (Ultralytics)\n",
      "  4. Haar Cascade (OpenCV)\n",
      "  5. Background Subtraction + Contours\n",
      "  0. Run model comparison tool\n",
      "  q. Quit\n",
      "\n",
      "🔍 Running model comparison...\n",
      "Initializing detection models...\n",
      "✓ HOG + SVM initialized\n",
      "✓ YOLOv8 initialized\n",
      "✗ MobileNet SSD files not found (download required)\n",
      "✓ Haar Cascade initialized\n",
      "✓ Background Subtraction initialized\n",
      "\n",
      "Model Performance Comparison:\n",
      "--------------------------------------------------\n",
      "Switched to: HOG + SVM (OpenCV)\n",
      "HOG + SVM (OpenCV):\n",
      "  Detections: 0\n",
      "  FPS: 2.1\n",
      "  Avg Confidence: 0.00\n",
      "\n",
      "Switched to: YOLOv8 (Ultralytics)\n",
      "YOLOv8 (Ultralytics):\n",
      "  Detections: 1\n",
      "  FPS: 30.3\n",
      "  Avg Confidence: 0.76\n",
      "\n",
      "Switched to: Haar Cascade (OpenCV)\n",
      "Haar Cascade (OpenCV):\n",
      "  Detections: 0\n",
      "  FPS: 44.5\n",
      "  Avg Confidence: 0.00\n",
      "\n",
      "Switched to: Background Subtraction + Contours\n",
      "Background Subtraction + Contours:\n",
      "  Detections: 0\n",
      "  FPS: 34.5\n",
      "  Avg Confidence: 0.00\n",
      "\n",
      "Recommendations:\n",
      "  Best Speed: Haar Cascade (OpenCV) (44.5 FPS)\n",
      "  Most Detections: YOLOv8 (Ultralytics) (1 people)\n",
      "\n",
      "🎯 Starting detection with: HOG + SVM (OpenCV)\n",
      "==================================================\n",
      "Controls during detection:\n",
      "  q - Quit\n",
      "  s - Save screenshot\n",
      "  r - Reset statistics\n",
      "  1-5 - Switch between models\n",
      "==================================================\n",
      "Switched to: HOG + SVM (OpenCV)\n",
      "Switched to: YOLOv8 (Ultralytics)\n",
      "ALERT!\n",
      "[18:29:47] 🚨 ALERTS: Person 7 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:29:53] 🚨 ALERTS: Person 7 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:29:58] 🚨 ALERTS: Person 11 is approaching the camera!\n",
      "ALERT!\n",
      "[18:30:05] 🚨 ALERTS: Person 14 is pacing back and forth!\n",
      "Switched to: HOG + SVM (OpenCV)\n",
      "Switched to: YOLOv8 (Ultralytics)\n",
      "ALERT!\n",
      "[18:30:13] 🚨 ALERTS: Person 14 is pacing back and forth!\n",
      "Model 'mobilenet' not available\n",
      "Switched to: Haar Cascade (OpenCV)\n",
      "Model 'mobilenet' not available\n",
      "Switched to: YOLOv8 (Ultralytics)\n",
      "ALERT!\n",
      "[18:30:21] 🚨 ALERTS: Person 14 is pacing back and forth!\n",
      "Switched to: Background Subtraction + Contours\n",
      "ALERT!\n",
      "[18:30:26] 🚨 ALERTS: Person 40 is pacing back and forth!, Person 45 is pacing back and forth!\n",
      "Switched to: YOLOv8 (Ultralytics)\n",
      "ALERT!\n",
      "[18:30:31] 🚨 ALERTS: Person 28 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:30:36] 🚨 ALERTS: Person 28 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:30:42] 🚨 ALERTS: Person 28 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:30:48] 🚨 ALERTS: Person 28 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:30:53] 🚨 ALERTS: Person 28 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:30:58] 🚨 ALERTS: Person 28 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:31:04] 🚨 ALERTS: Person 28 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:31:09] 🚨 ALERTS: Person 28 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:31:15] 🚨 ALERTS: Person 28 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:31:20] 🚨 ALERTS: Person 47 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:31:26] 🚨 ALERTS: Person 47 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:31:31] 🚨 ALERTS: Person 47 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:31:36] 🚨 ALERTS: Person 47 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:31:42] 🚨 ALERTS: Person 47 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:31:47] 🚨 ALERTS: Person 47 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:31:52] 🚨 ALERTS: Person 47 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:31:58] 🚨 ALERTS: Person 47 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:32:03] 🚨 ALERTS: Person 47 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:32:08] 🚨 ALERTS: Person 47 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:32:13] 🚨 ALERTS: Person 47 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:32:19] 🚨 ALERTS: Person 47 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:32:25] 🚨 ALERTS: Person 47 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:32:30] 🚨 ALERTS: Person 47 is pacing back and forth!\n",
      "\n",
      "⏹️  Stopping detection system...\n",
      "✅ Person detection system stopped\n",
      "\n",
      "🔄 Would you like to try another model? (y/n): 👋 Thanks for using the detection system!\n"
     ]
    }
   ],
   "source": [
    "def interactive_model_selection():\n",
    "    \"\"\"Interactive model selection and testing\"\"\"\n",
    "    print(\"🎯 Person Detection System - Interactive Model Selection\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Initialize detector to check available models\n",
    "    detector = MultiModelPersonDetector()\n",
    "\n",
    "    print(\"\\nAvailable Detection Models:\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    available_models = []\n",
    "    for i, (model_key, model_name) in enumerate(detector.models.items(), 1):\n",
    "        if model_key in detector.model_objects:\n",
    "            print(f\"  {i}. {model_name} ✓\")\n",
    "            available_models.append((i, model_key, model_name))\n",
    "        else:\n",
    "            print(f\"  {i}. {model_name} ✗ (Not available)\")\n",
    "\n",
    "    if not available_models:\n",
    "        print(\"\\n❌ No models available! Please check your installation.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n📊 Quick Performance Test:\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # Quick performance test\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if cap.isOpened():\n",
    "        ret, test_frame = cap.read()\n",
    "        cap.release()\n",
    "\n",
    "        if ret:\n",
    "            performance_results = {}\n",
    "            for _, model_key, model_name in available_models:\n",
    "                detector.switch_model(model_key)\n",
    "                start_time = time.time()\n",
    "                boxes, weights = detector.detect_people(test_frame)\n",
    "                detection_time = time.time() - start_time\n",
    "                fps = 1.0 / detection_time if detection_time > 0 else 0\n",
    "\n",
    "                performance_results[model_key] = {\n",
    "                    'name': model_name,\n",
    "                    'detections': len(boxes),\n",
    "                    'fps': fps,\n",
    "                    'avg_confidence': np.mean(weights) if len(weights) > 0 else 0\n",
    "                }\n",
    "\n",
    "                print(f\"  {model_name}: {len(boxes)} detections, {fps:.1f} FPS\")\n",
    "        else:\n",
    "            print(\"  Could not capture test frame from webcam\")\n",
    "    else:\n",
    "        print(\"  Could not access webcam for performance test\")\n",
    "\n",
    "    print(f\"\\n🚀 Choose a model to start detection:\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    for num, model_key, model_name in available_models:\n",
    "        print(f\"  {num}. {model_name}\")\n",
    "\n",
    "    print(\"  0. Run model comparison tool\")\n",
    "    print(\"  q. Quit\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            choice = input(f\"\\nEnter your choice (1-{len(available_models)}, 0, or q): \").strip().lower()\n",
    "\n",
    "            if choice == 'q':\n",
    "                print(\"👋 Goodbye!\")\n",
    "                return\n",
    "            elif choice == '0':\n",
    "                print(\"\\n🔍 Running model comparison...\")\n",
    "                compare_models()\n",
    "                continue\n",
    "\n",
    "            choice_num = int(choice)\n",
    "            if 1 <= choice_num <= len(available_models):\n",
    "                selected_model = available_models[choice_num - 1]\n",
    "                model_key = selected_model[1]\n",
    "                model_name = selected_model[2]\n",
    "\n",
    "                print(f\"\\n🎯 Starting detection with: {model_name}\")\n",
    "                print(\"=\" * 50)\n",
    "                print(\"Controls during detection:\")\n",
    "                print(\"  q - Quit\")\n",
    "                print(\"  s - Save screenshot\")\n",
    "                print(\"  r - Reset statistics\")\n",
    "                print(\"  1-5 - Switch between models\")\n",
    "                print(\"=\" * 50)\n",
    "\n",
    "                # Start detection with selected model\n",
    "                detector.switch_model(model_key)\n",
    "\n",
    "                # Modified detection function to start with selected model\n",
    "                def run_with_selected_model():\n",
    "                    cap = cv2.VideoCapture(0)\n",
    "                    if not cap.isOpened():\n",
    "                        print(\"❌ Error: Could not open webcam\")\n",
    "                        return\n",
    "\n",
    "                    screenshot_count = 0\n",
    "\n",
    "                    try:\n",
    "                        while True:\n",
    "                            ret, frame = cap.read()\n",
    "                            if not ret:\n",
    "                                print(\"❌ Error: Could not read frame\")\n",
    "                                break\n",
    "\n",
    "                            # Detect people\n",
    "                            boxes, weights = detector.detect_people(frame)\n",
    "                            detector.detection_count += len(boxes)\n",
    "\n",
    "                            # Track movement and get alerts\n",
    "                            frame_center = (frame.shape[0], frame.shape[1])\n",
    "                            alerts = detector.track_movement(boxes, frame_center)\n",
    "\n",
    "                            # Handle alerts\n",
    "                            current_time = time.time()\n",
    "                            if alerts and current_time - detector.last_alert_time > detector.alert_cooldown:\n",
    "                                detector.play_alert_sound()\n",
    "                                detector.last_alert_time = current_time\n",
    "                                print(f\"[{datetime.now().strftime('%H:%M:%S')}] 🚨 ALERTS: {', '.join(alerts)}\")\n",
    "\n",
    "                            # Draw detections and information\n",
    "                            frame = detector.draw_detections(frame, boxes, alerts)\n",
    "\n",
    "                            # Display frame\n",
    "                            cv2.imshow('Person Detection - Security Monitor', frame)\n",
    "\n",
    "                            # Handle key presses\n",
    "                            key = cv2.waitKey(1) & 0xFF\n",
    "                            if key == ord('q'):\n",
    "                                break\n",
    "                            elif key == ord('s'):\n",
    "                                screenshot_count += 1\n",
    "                                filename = f\"data/screenshot_{screenshot_count}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jpg\"\n",
    "                                cv2.imwrite(filename, frame)\n",
    "                                print(f\"📸 Screenshot saved: {filename}\")\n",
    "                            elif key == ord('r'):\n",
    "                                detector.detection_count = 0\n",
    "                                detector.approach_alerts = 0\n",
    "                                detector.pacing_alerts = 0\n",
    "                                detector.person_tracks.clear()\n",
    "                                print(\"🔄 Statistics reset\")\n",
    "                            elif key == ord('1'):\n",
    "                                detector.switch_model('hog')\n",
    "                            elif key == ord('2'):\n",
    "                                detector.switch_model('yolo')\n",
    "                            elif key == ord('3'):\n",
    "                                detector.switch_model('mobilenet')\n",
    "                            elif key == ord('4'):\n",
    "                                detector.switch_model('cascade')\n",
    "                            elif key == ord('5'):\n",
    "                                detector.switch_model('background_subtraction')\n",
    "\n",
    "                    except KeyboardInterrupt:\n",
    "                        print(\"\\n⏹️  Stopping detection system...\")\n",
    "\n",
    "                    finally:\n",
    "                        cap.release()\n",
    "                        cv2.destroyAllWindows()\n",
    "                        print(\"✅ Person detection system stopped\")\n",
    "\n",
    "                run_with_selected_model()\n",
    "\n",
    "                # Ask if user wants to try another model\n",
    "                print(f\"\\n🔄 Would you like to try another model? (y/n): \", end=\"\")\n",
    "                if input().strip().lower() != 'y':\n",
    "                    print(\"👋 Thanks for using the detection system!\")\n",
    "                    break\n",
    "\n",
    "            else:\n",
    "                print(f\"❌ Invalid choice. Please enter a number between 1 and {len(available_models)}\")\n",
    "\n",
    "        except ValueError:\n",
    "            print(\"❌ Invalid input. Please enter a number or 'q' to quit\")\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n👋 Goodbye!\")\n",
    "            break\n",
    "\n",
    "# Run the interactive model selection\n",
    "interactive_model_selection()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16954dce0a2c46a",
   "metadata": {},
   "source": [
    "# Run the Detection System\n",
    "\n",
    "Execute the cell below to start the person detection system with interactive model selection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e5f511be53257fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T22:32:38.262228Z",
     "start_time": "2025-07-17T22:32:35.761921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 OpenCV Person Detection System\n",
      "==================================================\n",
      "This system will:\n",
      "• Detect people using your webcam\n",
      "• Track movement patterns\n",
      "• Alert when someone approaches your computer\n",
      "• Alert when someone is pacing back and forth\n",
      "• Allow you to test different detection models\n",
      "==================================================\n",
      "\n",
      "🎯 Starting Interactive Model Selection...\n",
      "🎯 Person Detection System - Interactive Model Selection\n",
      "============================================================\n",
      "Initializing detection models...\n",
      "✓ HOG + SVM initialized\n",
      "✓ YOLOv8 initialized\n",
      "✗ MobileNet SSD files not found (download required)\n",
      "✓ Haar Cascade initialized\n",
      "✓ Background Subtraction initialized\n",
      "\n",
      "Available Detection Models:\n",
      "------------------------------\n",
      "  1. HOG + SVM (OpenCV) ✓\n",
      "  2. YOLOv8 (Ultralytics) ✓\n",
      "  3. MobileNet SSD (OpenCV DNN) ✗ (Not available)\n",
      "  4. Haar Cascade (OpenCV) ✓\n",
      "  5. Background Subtraction + Contours ✓\n",
      "\n",
      "📊 Quick Performance Test:\n",
      "------------------------------\n",
      "Switched to: HOG + SVM (OpenCV)\n",
      "  HOG + SVM (OpenCV): 0 detections, 2.1 FPS\n",
      "Switched to: YOLOv8 (Ultralytics)\n",
      "  YOLOv8 (Ultralytics): 1 detections, 25.6 FPS\n",
      "Switched to: Haar Cascade (OpenCV)\n",
      "  Haar Cascade (OpenCV): 0 detections, 42.6 FPS\n",
      "Switched to: Background Subtraction + Contours\n",
      "  Background Subtraction + Contours: 0 detections, 32.7 FPS\n",
      "\n",
      "🚀 Choose a model to start detection:\n",
      "----------------------------------------\n",
      "  1. HOG + SVM (OpenCV)\n",
      "  2. YOLOv8 (Ultralytics)\n",
      "  4. Haar Cascade (OpenCV)\n",
      "  5. Background Subtraction + Contours\n",
      "  0. Run model comparison tool\n",
      "  q. Quit\n",
      "\n",
      "👋 Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Main execution cell - Run this to start the detection system\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🚀 OpenCV Person Detection System\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"This system will:\")\n",
    "    print(\"• Detect people using your webcam\")\n",
    "    print(\"• Track movement patterns\")\n",
    "    print(\"• Alert when someone approaches your computer\")\n",
    "    print(\"• Alert when someone is pacing back and forth\")\n",
    "    print(\"• Allow you to test different detection models\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Create data directory if it doesn't exist\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "    # Ask user which model to try\n",
    "    print(\"\\n🎯 Starting Interactive Model Selection...\")\n",
    "    interactive_model_selection()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
