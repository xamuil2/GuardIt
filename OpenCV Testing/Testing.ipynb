{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de7db694f6833c07",
   "metadata": {},
   "source": [
    "# Person Detection and Movement Tracking System\n",
    "\n",
    "This system uses OpenCV to detect people via webcam and tracks their movements to identify:\n",
    "- People walking back and forth\n",
    "- Anyone approaching your computer\n",
    "- Real-time alerts for suspicious activity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d1f5a12588bc4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T22:29:24.764160Z",
     "start_time": "2025-07-17T22:29:24.744768Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import pygame\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Initialize pygame for sound alerts\n",
    "pygame.mixer.init()\n",
    "\n",
    "class MultiModelPersonDetector:\n",
    "    def __init__(self):\n",
    "        # Available detection models\n",
    "        self.models = {\n",
    "            'hog': 'HOG + SVM (OpenCV)',\n",
    "            'yolo': 'YOLOv8 (Ultralytics)',\n",
    "            'mobilenet': 'MobileNet SSD (OpenCV DNN)',\n",
    "            'cascade': 'Haar Cascade (OpenCV)',\n",
    "            'background_subtraction': 'Background Subtraction + Contours'\n",
    "        }\n",
    "\n",
    "        self.current_model = 'yolo'\n",
    "        self.model_objects = {}\n",
    "\n",
    "        # Initialize all models\n",
    "        self._initialize_models()\n",
    "\n",
    "        # Movement tracking\n",
    "        self.person_tracks = {}\n",
    "        self.track_id = 0\n",
    "        self.approach_threshold = 0.3\n",
    "        self.oscillation_threshold = 3\n",
    "\n",
    "        # Alert settings\n",
    "        self.last_alert_time = 0\n",
    "        self.alert_cooldown = 5\n",
    "\n",
    "        # Statistics\n",
    "        self.detection_count = 0\n",
    "        self.approach_alerts = 0\n",
    "        self.pacing_alerts = 0\n",
    "\n",
    "        # Performance tracking\n",
    "        self.fps_history = deque(maxlen=30)\n",
    "        self.detection_confidence = deque(maxlen=30)\n",
    "\n",
    "    def _initialize_models(self):\n",
    "        \"\"\"Initialize all detection models\"\"\"\n",
    "        print(\"Initializing detection models...\")\n",
    "\n",
    "        # 1. HOG + SVM\n",
    "        try:\n",
    "            hog = cv2.HOGDescriptor()\n",
    "            hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "            self.model_objects['hog'] = hog\n",
    "            print(\"‚úì HOG + SVM initialized\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚úó HOG + SVM failed: {e}\")\n",
    "\n",
    "        # 2. YOLOv8\n",
    "        try:\n",
    "            from ultralytics import YOLO\n",
    "            import torch\n",
    "            device = 'mps' if hasattr(torch, 'backends') and torch.backends.mps.is_available() else 'cpu'\n",
    "            yolo_model = YOLO('yolov8n.pt')\n",
    "            yolo_model.to(device)\n",
    "            self.model_objects['yolo'] = yolo_model\n",
    "            print(f\"‚úì YOLOv8 initialized on device: {device}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚úó YOLOv8 failed: {e}\")\n",
    "\n",
    "        # 3. MobileNet SSD\n",
    "        try:\n",
    "            # Download MobileNet SSD model if not exists\n",
    "            model_dir = Path(\"models\")\n",
    "            model_dir.mkdir(exist_ok=True)\n",
    "\n",
    "            config_path = model_dir / \"MobileNetSSD_deploy.prototxt\"\n",
    "            weights_path = model_dir / \"MobileNetSSD_deploy.caffemodel\"\n",
    "\n",
    "            # For demo purposes, we'll use a simpler approach\n",
    "            # You can manually download these files if needed\n",
    "            try:\n",
    "                net = cv2.dnn.readNetFromCaffe(str(config_path), str(weights_path))\n",
    "                self.model_objects['mobilenet'] = net\n",
    "                print(\"‚úì MobileNet SSD initialized\")\n",
    "            except:\n",
    "                print(\"‚úó MobileNet SSD files not found (download required)\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚úó MobileNet SSD failed: {e}\")\n",
    "\n",
    "        # 4. Haar Cascade\n",
    "        try:\n",
    "            # Use correct path to cascade file\n",
    "            cascade_path = os.path.join(cv2.data.haarcascades, 'haarcascade_fullbody.xml')\n",
    "            if os.path.exists(cascade_path):\n",
    "                cascade = cv2.CascadeClassifier(cascade_path)\n",
    "                self.model_objects['cascade'] = cascade\n",
    "                print(\"‚úì Haar Cascade initialized\")\n",
    "            else:\n",
    "                print(\"‚úó Haar Cascade file not found\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚úó Haar Cascade failed: {e}\")\n",
    "\n",
    "        # 5. Background Subtraction\n",
    "        try:\n",
    "            bg_subtractor = cv2.createBackgroundSubtractorMOG2(detectShadows=True)\n",
    "            self.model_objects['background_subtraction'] = bg_subtractor\n",
    "            print(\"‚úì Background Subtraction initialized\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚úó Background Subtraction failed: {e}\")\n",
    "\n",
    "    def switch_model(self, model_name):\n",
    "        \"\"\"Switch to a different detection model\"\"\"\n",
    "        if model_name in self.models and model_name in self.model_objects:\n",
    "            self.current_model = model_name\n",
    "            print(f\"Switched to: {self.models[model_name]}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Model '{model_name}' not available\")\n",
    "            return False\n",
    "\n",
    "    def detect_people_hog(self, frame):\n",
    "        \"\"\"HOG + SVM detection\"\"\"\n",
    "        if 'hog' not in self.model_objects:\n",
    "            return [], []\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        boxes, weights = self.model_objects['hog'].detectMultiScale(\n",
    "            gray,\n",
    "            winStride=(8, 8),\n",
    "            padding=(32, 32),\n",
    "            scale=1.05\n",
    "        )\n",
    "\n",
    "        # Convert to [x1, y1, x2, y2] format\n",
    "        boxes = np.array([[x, y, x + w, y + h] for (x, y, w, h) in boxes])\n",
    "        return boxes, weights\n",
    "\n",
    "    def detect_people_yolo(self, frame):\n",
    "        \"\"\"YOLOv8 detection\"\"\"\n",
    "        if 'yolo' not in self.model_objects:\n",
    "            return [], []\n",
    "\n",
    "        results = self.model_objects['yolo'](frame, verbose=False)\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "\n",
    "        for result in results:\n",
    "            for box in result.boxes:\n",
    "                if box.cls == 0:  # Person class\n",
    "                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                    boxes.append([int(x1), int(y1), int(x2), int(y2)])\n",
    "                    confidences.append(float(box.conf))\n",
    "\n",
    "        return np.array(boxes), np.array(confidences)\n",
    "\n",
    "    def detect_people_mobilenet(self, frame):\n",
    "        \"\"\"MobileNet SSD detection\"\"\"\n",
    "        if 'mobilenet' not in self.model_objects:\n",
    "            return [], []\n",
    "\n",
    "        h, w = frame.shape[:2]\n",
    "        blob = cv2.dnn.blobFromImage(frame, 0.007843, (300, 300), (127.5, 127.5, 127.5))\n",
    "\n",
    "        net = self.model_objects['mobilenet']\n",
    "        net.setInput(blob)\n",
    "        detections = net.forward()\n",
    "\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "\n",
    "        for i in range(detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            class_id = int(detections[0, 0, i, 1])\n",
    "\n",
    "            if class_id == 15 and confidence > 0.5:  # Person class\n",
    "                x1 = int(detections[0, 0, i, 3] * w)\n",
    "                y1 = int(detections[0, 0, i, 4] * h)\n",
    "                x2 = int(detections[0, 0, i, 5] * w)\n",
    "                y2 = int(detections[0, 0, i, 6] * h)\n",
    "\n",
    "                boxes.append([x1, y1, x2, y2])\n",
    "                confidences.append(confidence)\n",
    "\n",
    "        return np.array(boxes), np.array(confidences)\n",
    "\n",
    "    def detect_people_cascade(self, frame):\n",
    "        \"\"\"Haar Cascade detection\"\"\"\n",
    "        if 'cascade' not in self.model_objects:\n",
    "            return [], []\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        bodies = self.model_objects['cascade'].detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=3,\n",
    "            minSize=(30, 30)\n",
    "        )\n",
    "\n",
    "        # Convert to [x1, y1, x2, y2] format\n",
    "        boxes = np.array([[x, y, x + w, y + h] for (x, y, w, h) in bodies])\n",
    "        weights = np.ones(len(boxes))  # No confidence scores from cascade\n",
    "\n",
    "        return boxes, weights\n",
    "\n",
    "    def detect_people_background_subtraction(self, frame):\n",
    "        \"\"\"Background subtraction with contour detection\"\"\"\n",
    "        if 'background_subtraction' not in self.model_objects:\n",
    "            return [], []\n",
    "\n",
    "        # Apply background subtraction\n",
    "        fg_mask = self.model_objects['background_subtraction'].apply(frame)\n",
    "\n",
    "        # Morphological operations to clean up the mask\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "        fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "\n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area > 500:  # Filter small contours\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                # Filter by aspect ratio (rough person shape)\n",
    "                aspect_ratio = h / w\n",
    "                if 1.2 < aspect_ratio < 4.0:\n",
    "                    boxes.append([x, y, x + w, y + h])\n",
    "                    confidences.append(area / 10000)  # Use area as confidence\n",
    "\n",
    "        return np.array(boxes), np.array(confidences)\n",
    "\n",
    "    def detect_people(self, frame):\n",
    "        \"\"\"Detect people using the current model\"\"\"\n",
    "        start_time = time.time()\n",
    "\n",
    "        if self.current_model == 'hog':\n",
    "            boxes, weights = self.detect_people_hog(frame)\n",
    "        elif self.current_model == 'yolo':\n",
    "            boxes, weights = self.detect_people_yolo(frame)\n",
    "        elif self.current_model == 'mobilenet':\n",
    "            boxes, weights = self.detect_people_mobilenet(frame)\n",
    "        elif self.current_model == 'cascade':\n",
    "            boxes, weights = self.detect_people_cascade(frame)\n",
    "        elif self.current_model == 'background_subtraction':\n",
    "            boxes, weights = self.detect_people_background_subtraction(frame)\n",
    "        else:\n",
    "            boxes, weights = [], []\n",
    "\n",
    "        # Calculate FPS\n",
    "        detection_time = time.time() - start_time\n",
    "        fps = 1.0 / detection_time if detection_time > 0 else 0\n",
    "        self.fps_history.append(fps)\n",
    "\n",
    "        # Store average confidence\n",
    "        if len(weights) > 0:\n",
    "            avg_confidence = np.mean(weights)\n",
    "            self.detection_confidence.append(avg_confidence)\n",
    "\n",
    "        return boxes, weights\n",
    "\n",
    "    def calculate_distance_to_camera(self, box):\n",
    "        \"\"\"Calculate relative distance to camera based on bounding box size\"\"\"\n",
    "        x1, y1, x2, y2 = box\n",
    "        w = x2 - x1\n",
    "        h = y2 - y1\n",
    "        # Larger boxes are closer to camera\n",
    "        return 1.0 / (w * h / 10000)  # Normalized distance metric\n",
    "\n",
    "    def track_movement(self, boxes, frame_center):\n",
    "        \"\"\"Track person movement and detect patterns\"\"\"\n",
    "        current_time = time.time()\n",
    "        frame_height, frame_width = frame_center\n",
    "\n",
    "        alerts = []\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box\n",
    "            center_x = (x1 + x2) // 2\n",
    "            center_y = (y1 + y2) // 2\n",
    "\n",
    "            # Calculate distance to camera\n",
    "            distance = self.calculate_distance_to_camera(box)\n",
    "\n",
    "            # Find closest existing track or create new one\n",
    "            min_distance = float('inf')\n",
    "            closest_track = None\n",
    "\n",
    "            for track_id, track_data in self.person_tracks.items():\n",
    "                if track_data['positions']:\n",
    "                    last_pos = track_data['positions'][-1]\n",
    "                    dist = np.sqrt((center_x - last_pos[0])**2 + (center_y - last_pos[1])**2)\n",
    "                    if dist < min_distance and dist < 100:  # Maximum movement threshold\n",
    "                        min_distance = dist\n",
    "                        closest_track = track_id\n",
    "\n",
    "            if closest_track is None:\n",
    "                # Create new track\n",
    "                self.track_id += 1\n",
    "                self.person_tracks[self.track_id] = {\n",
    "                    'positions': deque(maxlen=30),  # Keep last 30 positions\n",
    "                    'distances': deque(maxlen=30),\n",
    "                    'timestamps': deque(maxlen=30),\n",
    "                    'direction_changes': 0,\n",
    "                    'last_direction': None,\n",
    "                    'approaching': False\n",
    "                }\n",
    "                closest_track = self.track_id\n",
    "\n",
    "            # Update track\n",
    "            track = self.person_tracks[closest_track]\n",
    "            track['positions'].append((center_x, center_y))\n",
    "            track['distances'].append(distance)\n",
    "            track['timestamps'].append(current_time)\n",
    "\n",
    "            # Detect approaching behavior\n",
    "            if len(track['distances']) >= 5:\n",
    "                recent_distances = list(track['distances'])[-5:]\n",
    "                if all(recent_distances[i] < recent_distances[i-1] for i in range(1, len(recent_distances))):\n",
    "                    if distance < self.approach_threshold and not track['approaching']:\n",
    "                        track['approaching'] = True\n",
    "                        alerts.append(f\"Person {closest_track} is approaching the camera!\")\n",
    "                        self.approach_alerts += 1\n",
    "                elif distance > self.approach_threshold:\n",
    "                    track['approaching'] = False\n",
    "\n",
    "            # Detect pacing/oscillation\n",
    "            if len(track['positions']) >= 3:\n",
    "                positions = list(track['positions'])\n",
    "                # Calculate movement direction\n",
    "                recent_direction = \"left\" if positions[-1][0] < positions[-3][0] else \"right\"\n",
    "\n",
    "                if track['last_direction'] and track['last_direction'] != recent_direction:\n",
    "                    track['direction_changes'] += 1\n",
    "\n",
    "                    if track['direction_changes'] >= self.oscillation_threshold:\n",
    "                        alerts.append(f\"Person {closest_track} is pacing back and forth!\")\n",
    "                        self.pacing_alerts += 1\n",
    "                        track['direction_changes'] = 0  # Reset counter\n",
    "\n",
    "                track['last_direction'] = recent_direction\n",
    "\n",
    "        # Clean up old tracks\n",
    "        current_time = time.time()\n",
    "        tracks_to_remove = []\n",
    "        for track_id, track_data in self.person_tracks.items():\n",
    "            if track_data['timestamps'] and current_time - track_data['timestamps'][-1] > 5:\n",
    "                tracks_to_remove.append(track_id)\n",
    "\n",
    "        for track_id in tracks_to_remove:\n",
    "            del self.person_tracks[track_id]\n",
    "\n",
    "        return alerts\n",
    "\n",
    "    def play_alert_sound(self):\n",
    "        \"\"\"Play alert sound (beep)\"\"\"\n",
    "        try:\n",
    "            # Create a simple beep sound\n",
    "            sample_rate = 22050\n",
    "            duration = 0.5\n",
    "            frequency = 800\n",
    "\n",
    "            frames = int(duration * sample_rate)\n",
    "            arr = np.sin(2 * np.pi * frequency * np.linspace(0, duration, frames))\n",
    "            arr = (arr * 32767).astype(np.int16)\n",
    "\n",
    "            sound = pygame.sndarray.make_sound(arr)\n",
    "            sound.play()\n",
    "        except:\n",
    "            print(\"ALERT!\")  # Fallback if sound fails\n",
    "\n",
    "    def draw_detections(self, frame, boxes, alerts):\n",
    "        \"\"\"Draw bounding boxes and information on frame\"\"\"\n",
    "        for i, box in enumerate(boxes):\n",
    "            x1, y1, x2, y2 = box\n",
    "\n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "            # Calculate and display distance\n",
    "            distance = self.calculate_distance_to_camera(box)\n",
    "            cv2.putText(frame, f\"Dist: {distance:.2f}\", (x1, y1-10),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "        # Display current model\n",
    "        cv2.putText(frame, f\"Model: {self.models[self.current_model]}\",\n",
    "                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "\n",
    "        # Display FPS\n",
    "        if self.fps_history:\n",
    "            avg_fps = np.mean(list(self.fps_history))\n",
    "            cv2.putText(frame, f\"FPS: {avg_fps:.1f}\",\n",
    "                       (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "\n",
    "        # Display alerts\n",
    "        for i, alert in enumerate(alerts):\n",
    "            cv2.putText(frame, alert, (10, 90 + i*30),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "        # Display statistics\n",
    "        stats = [\n",
    "            f\"People detected: {len(boxes)}\",\n",
    "            f\"Total detections: {self.detection_count}\",\n",
    "            f\"Approach alerts: {self.approach_alerts}\",\n",
    "            f\"Pacing alerts: {self.pacing_alerts}\"\n",
    "        ]\n",
    "\n",
    "        for i, stat in enumerate(stats):\n",
    "            cv2.putText(frame, stat, (10, frame.shape[0] - 120 + i*20),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "        # Model switching instructions\n",
    "        instructions = [\n",
    "            \"Model Controls:\",\n",
    "            \"1-HOG  2-YOLO  3-MobileNet\",\n",
    "            \"4-Cascade  5-Background Sub\"\n",
    "        ]\n",
    "\n",
    "        for i, instruction in enumerate(instructions):\n",
    "            cv2.putText(frame, instruction, (frame.shape[1] - 300, 30 + i*20),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (200, 200, 200), 1)\n",
    "\n",
    "        return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c17d7c09ae22a724",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T22:29:24.773290Z",
     "start_time": "2025-07-17T22:29:24.769284Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_person_detection():\n",
    "    \"\"\"Main function to run the person detection system\"\"\"\n",
    "    detector = MultiModelPersonDetector()\n",
    "\n",
    "    # Initialize webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam\")\n",
    "        return\n",
    "\n",
    "    print(\"Person Detection System Started\")\n",
    "    print(\"Press 'q' to quit\")\n",
    "    print(\"Press 's' to save screenshot\")\n",
    "    print(\"Press 'r' to reset statistics\")\n",
    "    print(\"Press '1-5' to switch between detection models:\")\n",
    "    print(\"  1 - HOG + SVM (Default)\")\n",
    "    print(\"  2 - YOLOv8 (Best accuracy)\")\n",
    "    print(\"  3 - MobileNet SSD\")\n",
    "    print(\"  4 - Haar Cascade\")\n",
    "    print(\"  5 - Background Subtraction\")\n",
    "\n",
    "    screenshot_count = 0\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Error: Could not read frame\")\n",
    "                break\n",
    "\n",
    "            # Detect people\n",
    "            boxes, weights = detector.detect_people(frame)\n",
    "            detector.detection_count += len(boxes)\n",
    "\n",
    "            # Track movement and get alerts\n",
    "            frame_center = (frame.shape[0], frame.shape[1])\n",
    "            alerts = detector.track_movement(boxes, frame_center)\n",
    "\n",
    "            # Handle alerts\n",
    "            current_time = time.time()\n",
    "            if alerts and current_time - detector.last_alert_time > detector.alert_cooldown:\n",
    "                detector.play_alert_sound()\n",
    "                detector.last_alert_time = current_time\n",
    "                print(f\"[{datetime.now().strftime('%H:%M:%S')}] ALERTS: {', '.join(alerts)}\")\n",
    "\n",
    "            # Draw detections and information\n",
    "            frame = detector.draw_detections(frame, boxes, alerts)\n",
    "\n",
    "            # Display frame\n",
    "            cv2.imshow('Person Detection - Security Monitor', frame)\n",
    "\n",
    "            # Handle key presses\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "            elif key == ord('s'):\n",
    "                screenshot_count += 1\n",
    "                filename = f\"data/screenshot_{screenshot_count}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jpg\"\n",
    "                cv2.imwrite(filename, frame)\n",
    "                print(f\"Screenshot saved: {filename}\")\n",
    "            elif key == ord('r'):\n",
    "                detector.detection_count = 0\n",
    "                detector.approach_alerts = 0\n",
    "                detector.pacing_alerts = 0\n",
    "                detector.person_tracks.clear()\n",
    "                print(\"Statistics reset\")\n",
    "            elif key == ord('1'):\n",
    "                detector.switch_model('hog')\n",
    "            elif key == ord('2'):\n",
    "                detector.switch_model('yolo')\n",
    "            elif key == ord('3'):\n",
    "                detector.switch_model('mobilenet')\n",
    "            elif key == ord('4'):\n",
    "                detector.switch_model('cascade')\n",
    "            elif key == ord('5'):\n",
    "                detector.switch_model('background_subtraction')\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nStopping detection system...\")\n",
    "\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"Person detection system stopped\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f7037997732b44c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T22:29:24.780351Z",
     "start_time": "2025-07-17T22:29:24.777561Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model comparison tool\n",
    "def compare_models():\n",
    "    \"\"\"Compare performance of different detection models\"\"\"\n",
    "    detector = MultiModelPersonDetector()\n",
    "\n",
    "    # Test each model on a sample frame\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam\")\n",
    "        return\n",
    "\n",
    "    ret, test_frame = cap.read()\n",
    "    cap.release()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Error: Could not capture test frame\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nModel Performance Comparison:\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for model_name in detector.models.keys():\n",
    "        if model_name in detector.model_objects:\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Switch to model and detect\n",
    "            detector.switch_model(model_name)\n",
    "            boxes, weights = detector.detect_people(test_frame)\n",
    "\n",
    "            detection_time = time.time() - start_time\n",
    "            fps = 1.0 / detection_time if detection_time > 0 else 0\n",
    "\n",
    "            results[model_name] = {\n",
    "                'detections': len(boxes),\n",
    "                'fps': fps,\n",
    "                'avg_confidence': np.mean(weights) if len(weights) > 0 else 0\n",
    "            }\n",
    "\n",
    "            print(f\"{detector.models[model_name]}:\")\n",
    "            print(f\"  Detections: {len(boxes)}\")\n",
    "            print(f\"  FPS: {fps:.1f}\")\n",
    "            print(f\"  Avg Confidence: {results[model_name]['avg_confidence']:.2f}\")\n",
    "            print()\n",
    "\n",
    "    # Recommend best model\n",
    "    if results:\n",
    "        best_fps = max(results.items(), key=lambda x: x[1]['fps'])\n",
    "        best_detections = max(results.items(), key=lambda x: x[1]['detections'])\n",
    "\n",
    "        print(\"Recommendations:\")\n",
    "        print(f\"  Best Speed: {detector.models[best_fps[0]]} ({best_fps[1]['fps']:.1f} FPS)\")\n",
    "        print(f\"  Most Detections: {detector.models[best_detections[0]]} ({best_detections[1]['detections']} people)\")\n",
    "\n",
    "# Uncomment to run model comparison\n",
    "# compare_models()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596453e22762cc1c",
   "metadata": {},
   "source": [
    "# Advanced Features\n",
    "\n",
    "You can extend this system with:\n",
    "- Face recognition to identify specific individuals\n",
    "- Motion history tracking\n",
    "- Email/SMS alerts for security breaches\n",
    "- Integration with home automation systems\n",
    "- Multiple camera support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9783d0aae4d9667",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T22:29:24.785404Z",
     "start_time": "2025-07-17T22:29:24.783628Z"
    }
   },
   "outputs": [],
   "source": [
    "# Optional: Analyze detection patterns\n",
    "def analyze_detection_patterns():\n",
    "    \"\"\"Analyze patterns in the detection data\"\"\"\n",
    "    # This would analyze stored detection data\n",
    "    # For now, just show how to visualize detection frequency\n",
    "\n",
    "    # Example visualization\n",
    "    times = [datetime.now().hour + np.random.randint(-2, 3) for _ in range(50)]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(times, bins=24, alpha=0.7, color='blue')\n",
    "    plt.xlabel('Hour of Day')\n",
    "    plt.ylabel('Detection Frequency')\n",
    "    plt.title('Person Detection Frequency by Hour')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# Uncomment to run analysis\n",
    "# analyze_detection_patterns()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df7ede98ceaf243",
   "metadata": {},
   "source": [
    "# Interactive Model Selection\n",
    "\n",
    "Run the cell below to start the person detection system with an interactive model selection menu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d595725d63c2f77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T22:32:35.752387Z",
     "start_time": "2025-07-17T22:29:24.788244Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Person Detection System - Interactive Model Selection\n",
      "============================================================\n",
      "Initializing detection models...\n",
      "‚úì HOG + SVM initialized\n",
      "‚úì YOLOv8 initialized\n",
      "‚úó MobileNet SSD files not found (download required)\n",
      "‚úì Haar Cascade initialized\n",
      "‚úì Background Subtraction initialized\n",
      "\n",
      "Available Detection Models:\n",
      "------------------------------\n",
      "  1. HOG + SVM (OpenCV) ‚úì\n",
      "  2. YOLOv8 (Ultralytics) ‚úì\n",
      "  3. MobileNet SSD (OpenCV DNN) ‚úó (Not available)\n",
      "  4. Haar Cascade (OpenCV) ‚úì\n",
      "  5. Background Subtraction + Contours ‚úì\n",
      "\n",
      "üìä Quick Performance Test:\n",
      "------------------------------\n",
      "Switched to: HOG + SVM (OpenCV)\n",
      "  HOG + SVM (OpenCV): 0 detections, 2.1 FPS\n",
      "Switched to: YOLOv8 (Ultralytics)\n",
      "  YOLOv8 (Ultralytics): 2 detections, 1.2 FPS\n",
      "Switched to: Haar Cascade (OpenCV)\n",
      "  Haar Cascade (OpenCV): 0 detections, 41.3 FPS\n",
      "Switched to: Background Subtraction + Contours\n",
      "  Background Subtraction + Contours: 0 detections, 30.8 FPS\n",
      "\n",
      "üöÄ Choose a model to start detection:\n",
      "----------------------------------------\n",
      "  1. HOG + SVM (OpenCV)\n",
      "  2. YOLOv8 (Ultralytics)\n",
      "  4. Haar Cascade (OpenCV)\n",
      "  5. Background Subtraction + Contours\n",
      "  0. Run model comparison tool\n",
      "  q. Quit\n",
      "\n",
      "üîç Running model comparison...\n",
      "Initializing detection models...\n",
      "‚úì HOG + SVM initialized\n",
      "‚úì YOLOv8 initialized\n",
      "‚úó MobileNet SSD files not found (download required)\n",
      "‚úì Haar Cascade initialized\n",
      "‚úì Background Subtraction initialized\n",
      "\n",
      "Model Performance Comparison:\n",
      "--------------------------------------------------\n",
      "Switched to: HOG + SVM (OpenCV)\n",
      "HOG + SVM (OpenCV):\n",
      "  Detections: 0\n",
      "  FPS: 2.1\n",
      "  Avg Confidence: 0.00\n",
      "\n",
      "Switched to: YOLOv8 (Ultralytics)\n",
      "YOLOv8 (Ultralytics):\n",
      "  Detections: 1\n",
      "  FPS: 30.3\n",
      "  Avg Confidence: 0.76\n",
      "\n",
      "Switched to: Haar Cascade (OpenCV)\n",
      "Haar Cascade (OpenCV):\n",
      "  Detections: 0\n",
      "  FPS: 44.5\n",
      "  Avg Confidence: 0.00\n",
      "\n",
      "Switched to: Background Subtraction + Contours\n",
      "Background Subtraction + Contours:\n",
      "  Detections: 0\n",
      "  FPS: 34.5\n",
      "  Avg Confidence: 0.00\n",
      "\n",
      "Recommendations:\n",
      "  Best Speed: Haar Cascade (OpenCV) (44.5 FPS)\n",
      "  Most Detections: YOLOv8 (Ultralytics) (1 people)\n",
      "\n",
      "üéØ Starting detection with: HOG + SVM (OpenCV)\n",
      "==================================================\n",
      "Controls during detection:\n",
      "  q - Quit\n",
      "  s - Save screenshot\n",
      "  r - Reset statistics\n",
      "  1-5 - Switch between models\n",
      "==================================================\n",
      "Switched to: HOG + SVM (OpenCV)\n",
      "Switched to: YOLOv8 (Ultralytics)\n",
      "ALERT!\n",
      "[18:29:47] üö® ALERTS: Person 7 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:29:53] üö® ALERTS: Person 7 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:29:58] üö® ALERTS: Person 11 is approaching the camera!\n",
      "ALERT!\n",
      "[18:30:05] üö® ALERTS: Person 14 is pacing back and forth!\n",
      "Switched to: HOG + SVM (OpenCV)\n",
      "Switched to: YOLOv8 (Ultralytics)\n",
      "ALERT!\n",
      "[18:30:13] üö® ALERTS: Person 14 is pacing back and forth!\n",
      "Model 'mobilenet' not available\n",
      "Switched to: Haar Cascade (OpenCV)\n",
      "Model 'mobilenet' not available\n",
      "Switched to: YOLOv8 (Ultralytics)\n",
      "ALERT!\n",
      "[18:30:21] üö® ALERTS: Person 14 is pacing back and forth!\n",
      "Switched to: Background Subtraction + Contours\n",
      "ALERT!\n",
      "[18:30:26] üö® ALERTS: Person 40 is pacing back and forth!, Person 45 is pacing back and forth!\n",
      "Switched to: YOLOv8 (Ultralytics)\n",
      "ALERT!\n",
      "[18:30:31] üö® ALERTS: Person 28 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:30:36] üö® ALERTS: Person 28 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:30:42] üö® ALERTS: Person 28 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:30:48] üö® ALERTS: Person 28 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:30:53] üö® ALERTS: Person 28 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:30:58] üö® ALERTS: Person 28 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:31:04] üö® ALERTS: Person 28 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:31:09] üö® ALERTS: Person 28 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:31:15] üö® ALERTS: Person 28 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:31:20] üö® ALERTS: Person 47 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:31:26] üö® ALERTS: Person 47 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:31:31] üö® ALERTS: Person 47 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:31:36] üö® ALERTS: Person 47 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:31:42] üö® ALERTS: Person 47 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:31:47] üö® ALERTS: Person 47 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:31:52] üö® ALERTS: Person 47 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:31:58] üö® ALERTS: Person 47 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:32:03] üö® ALERTS: Person 47 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:32:08] üö® ALERTS: Person 47 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:32:13] üö® ALERTS: Person 47 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:32:19] üö® ALERTS: Person 47 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:32:25] üö® ALERTS: Person 47 is pacing back and forth!\n",
      "ALERT!\n",
      "[18:32:30] üö® ALERTS: Person 47 is pacing back and forth!\n",
      "\n",
      "‚èπÔ∏è  Stopping detection system...\n",
      "‚úÖ Person detection system stopped\n",
      "\n",
      "üîÑ Would you like to try another model? (y/n): üëã Thanks for using the detection system!\n"
     ]
    }
   ],
   "source": [
    "def interactive_model_selection():\n",
    "    \"\"\"Interactive model selection and testing\"\"\"\n",
    "    print(\"üéØ Person Detection System - Interactive Model Selection\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Initialize detector to check available models\n",
    "    detector = MultiModelPersonDetector()\n",
    "\n",
    "    print(\"\\nAvailable Detection Models:\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    available_models = []\n",
    "    for i, (model_key, model_name) in enumerate(detector.models.items(), 1):\n",
    "        if model_key in detector.model_objects:\n",
    "            print(f\"  {i}. {model_name} ‚úì\")\n",
    "            available_models.append((i, model_key, model_name))\n",
    "        else:\n",
    "            print(f\"  {i}. {model_name} ‚úó (Not available)\")\n",
    "\n",
    "    if not available_models:\n",
    "        print(\"\\n‚ùå No models available! Please check your installation.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nüìä Quick Performance Test:\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # Quick performance test\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if cap.isOpened():\n",
    "        ret, test_frame = cap.read()\n",
    "        cap.release()\n",
    "\n",
    "        if ret:\n",
    "            performance_results = {}\n",
    "            for _, model_key, model_name in available_models:\n",
    "                detector.switch_model(model_key)\n",
    "                start_time = time.time()\n",
    "                boxes, weights = detector.detect_people(test_frame)\n",
    "                detection_time = time.time() - start_time\n",
    "                fps = 1.0 / detection_time if detection_time > 0 else 0\n",
    "\n",
    "                performance_results[model_key] = {\n",
    "                    'name': model_name,\n",
    "                    'detections': len(boxes),\n",
    "                    'fps': fps,\n",
    "                    'avg_confidence': np.mean(weights) if len(weights) > 0 else 0\n",
    "                }\n",
    "\n",
    "                print(f\"  {model_name}: {len(boxes)} detections, {fps:.1f} FPS\")\n",
    "        else:\n",
    "            print(\"  Could not capture test frame from webcam\")\n",
    "    else:\n",
    "        print(\"  Could not access webcam for performance test\")\n",
    "\n",
    "    print(f\"\\nüöÄ Choose a model to start detection:\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    for num, model_key, model_name in available_models:\n",
    "        print(f\"  {num}. {model_name}\")\n",
    "\n",
    "    print(\"  0. Run model comparison tool\")\n",
    "    print(\"  q. Quit\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            choice = input(f\"\\nEnter your choice (1-{len(available_models)}, 0, or q): \").strip().lower()\n",
    "\n",
    "            if choice == 'q':\n",
    "                print(\"üëã Goodbye!\")\n",
    "                return\n",
    "            elif choice == '0':\n",
    "                print(\"\\nüîç Running model comparison...\")\n",
    "                compare_models()\n",
    "                continue\n",
    "\n",
    "            choice_num = int(choice)\n",
    "            if 1 <= choice_num <= len(available_models):\n",
    "                selected_model = available_models[choice_num - 1]\n",
    "                model_key = selected_model[1]\n",
    "                model_name = selected_model[2]\n",
    "\n",
    "                print(f\"\\nüéØ Starting detection with: {model_name}\")\n",
    "                print(\"=\" * 50)\n",
    "                print(\"Controls during detection:\")\n",
    "                print(\"  q - Quit\")\n",
    "                print(\"  s - Save screenshot\")\n",
    "                print(\"  r - Reset statistics\")\n",
    "                print(\"  1-5 - Switch between models\")\n",
    "                print(\"=\" * 50)\n",
    "\n",
    "                # Start detection with selected model\n",
    "                detector.switch_model(model_key)\n",
    "\n",
    "                # Modified detection function to start with selected model\n",
    "                def run_with_selected_model():\n",
    "                    cap = cv2.VideoCapture(0)\n",
    "                    if not cap.isOpened():\n",
    "                        print(\"‚ùå Error: Could not open webcam\")\n",
    "                        return\n",
    "\n",
    "                    screenshot_count = 0\n",
    "\n",
    "                    try:\n",
    "                        while True:\n",
    "                            ret, frame = cap.read()\n",
    "                            if not ret:\n",
    "                                print(\"‚ùå Error: Could not read frame\")\n",
    "                                break\n",
    "\n",
    "                            # Detect people\n",
    "                            boxes, weights = detector.detect_people(frame)\n",
    "                            detector.detection_count += len(boxes)\n",
    "\n",
    "                            # Track movement and get alerts\n",
    "                            frame_center = (frame.shape[0], frame.shape[1])\n",
    "                            alerts = detector.track_movement(boxes, frame_center)\n",
    "\n",
    "                            # Handle alerts\n",
    "                            current_time = time.time()\n",
    "                            if alerts and current_time - detector.last_alert_time > detector.alert_cooldown:\n",
    "                                detector.play_alert_sound()\n",
    "                                detector.last_alert_time = current_time\n",
    "                                print(f\"[{datetime.now().strftime('%H:%M:%S')}] üö® ALERTS: {', '.join(alerts)}\")\n",
    "\n",
    "                            # Draw detections and information\n",
    "                            frame = detector.draw_detections(frame, boxes, alerts)\n",
    "\n",
    "                            # Display frame\n",
    "                            cv2.imshow('Person Detection - Security Monitor', frame)\n",
    "\n",
    "                            # Handle key presses\n",
    "                            key = cv2.waitKey(1) & 0xFF\n",
    "                            if key == ord('q'):\n",
    "                                break\n",
    "                            elif key == ord('s'):\n",
    "                                screenshot_count += 1\n",
    "                                filename = f\"data/screenshot_{screenshot_count}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jpg\"\n",
    "                                cv2.imwrite(filename, frame)\n",
    "                                print(f\"üì∏ Screenshot saved: {filename}\")\n",
    "                            elif key == ord('r'):\n",
    "                                detector.detection_count = 0\n",
    "                                detector.approach_alerts = 0\n",
    "                                detector.pacing_alerts = 0\n",
    "                                detector.person_tracks.clear()\n",
    "                                print(\"üîÑ Statistics reset\")\n",
    "                            elif key == ord('1'):\n",
    "                                detector.switch_model('hog')\n",
    "                            elif key == ord('2'):\n",
    "                                detector.switch_model('yolo')\n",
    "                            elif key == ord('3'):\n",
    "                                detector.switch_model('mobilenet')\n",
    "                            elif key == ord('4'):\n",
    "                                detector.switch_model('cascade')\n",
    "                            elif key == ord('5'):\n",
    "                                detector.switch_model('background_subtraction')\n",
    "\n",
    "                    except KeyboardInterrupt:\n",
    "                        print(\"\\n‚èπÔ∏è  Stopping detection system...\")\n",
    "\n",
    "                    finally:\n",
    "                        cap.release()\n",
    "                        cv2.destroyAllWindows()\n",
    "                        print(\"‚úÖ Person detection system stopped\")\n",
    "\n",
    "                run_with_selected_model()\n",
    "\n",
    "                # Ask if user wants to try another model\n",
    "                print(f\"\\nüîÑ Would you like to try another model? (y/n): \", end=\"\")\n",
    "                if input().strip().lower() != 'y':\n",
    "                    print(\"üëã Thanks for using the detection system!\")\n",
    "                    break\n",
    "\n",
    "            else:\n",
    "                print(f\"‚ùå Invalid choice. Please enter a number between 1 and {len(available_models)}\")\n",
    "\n",
    "        except ValueError:\n",
    "            print(\"‚ùå Invalid input. Please enter a number or 'q' to quit\")\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nüëã Goodbye!\")\n",
    "            break\n",
    "\n",
    "# Run the interactive model selection\n",
    "interactive_model_selection()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16954dce0a2c46a",
   "metadata": {},
   "source": [
    "# Run the Detection System\n",
    "\n",
    "Execute the cell below to start the person detection system with interactive model selection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e5f511be53257fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T22:32:38.262228Z",
     "start_time": "2025-07-17T22:32:35.761921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ OpenCV Person Detection System\n",
      "==================================================\n",
      "This system will:\n",
      "‚Ä¢ Detect people using your webcam\n",
      "‚Ä¢ Track movement patterns\n",
      "‚Ä¢ Alert when someone approaches your computer\n",
      "‚Ä¢ Alert when someone is pacing back and forth\n",
      "‚Ä¢ Allow you to test different detection models\n",
      "==================================================\n",
      "\n",
      "üéØ Starting Interactive Model Selection...\n",
      "üéØ Person Detection System - Interactive Model Selection\n",
      "============================================================\n",
      "Initializing detection models...\n",
      "‚úì HOG + SVM initialized\n",
      "‚úì YOLOv8 initialized\n",
      "‚úó MobileNet SSD files not found (download required)\n",
      "‚úì Haar Cascade initialized\n",
      "‚úì Background Subtraction initialized\n",
      "\n",
      "Available Detection Models:\n",
      "------------------------------\n",
      "  1. HOG + SVM (OpenCV) ‚úì\n",
      "  2. YOLOv8 (Ultralytics) ‚úì\n",
      "  3. MobileNet SSD (OpenCV DNN) ‚úó (Not available)\n",
      "  4. Haar Cascade (OpenCV) ‚úì\n",
      "  5. Background Subtraction + Contours ‚úì\n",
      "\n",
      "üìä Quick Performance Test:\n",
      "------------------------------\n",
      "Switched to: HOG + SVM (OpenCV)\n",
      "  HOG + SVM (OpenCV): 0 detections, 2.1 FPS\n",
      "Switched to: YOLOv8 (Ultralytics)\n",
      "  YOLOv8 (Ultralytics): 1 detections, 25.6 FPS\n",
      "Switched to: Haar Cascade (OpenCV)\n",
      "  Haar Cascade (OpenCV): 0 detections, 42.6 FPS\n",
      "Switched to: Background Subtraction + Contours\n",
      "  Background Subtraction + Contours: 0 detections, 32.7 FPS\n",
      "\n",
      "üöÄ Choose a model to start detection:\n",
      "----------------------------------------\n",
      "  1. HOG + SVM (OpenCV)\n",
      "  2. YOLOv8 (Ultralytics)\n",
      "  4. Haar Cascade (OpenCV)\n",
      "  5. Background Subtraction + Contours\n",
      "  0. Run model comparison tool\n",
      "  q. Quit\n",
      "\n",
      "üëã Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Main execution cell - Run this to start the detection system\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üöÄ OpenCV Person Detection System\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"This system will:\")\n",
    "    print(\"‚Ä¢ Detect people using your webcam\")\n",
    "    print(\"‚Ä¢ Track movement patterns\")\n",
    "    print(\"‚Ä¢ Alert when someone approaches your computer\")\n",
    "    print(\"‚Ä¢ Alert when someone is pacing back and forth\")\n",
    "    print(\"‚Ä¢ Allow you to test different detection models\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Create data directory if it doesn't exist\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "    # Ask user which model to try\n",
    "    print(\"\\nüéØ Starting Interactive Model Selection...\")\n",
    "    interactive_model_selection()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
